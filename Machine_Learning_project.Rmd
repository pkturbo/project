---
title: "Practical Machine Learning Project"
author: "pkturbo"
date: "July 21, 2015"
output: html_document
---
##Background##

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

##Data##

The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

First, let's load the libraries we need for the analysis:

```{r, results='hide'}
library(caret)
library(randomForest)
```

##Explore and clean the data set##

By looking at the raw data set, one can see that there are many entries that are either NA, DIV/0, or empty characters (i.e. ""). We can convert all of these to NAs when we read the file.

```{r}
train.Data <- read.csv(file = 'pml-training.csv',stringsAsFactors = FALSE,
                       na.strings = c("NA", "#DIV/0!", ""))
train.Data$classe <- as.factor(train.Data$classe)
```

Also, we note that many columns are composed nearly entirely of NA values, and that some rows (where `new_window`='yes') have many NA entires. Let's remove these rows and columns.

```{r}
train.Data2 <- train.Data[train.Data$new_window == "no",
                          c(7:11,37:49,60:68,84:86,102,113:124,140,151:160)]
```

Now the data set has no NA values at all.

##Classification model choice##

I have chosen to implement a **Random Forest** classification model. In random forests, there is **no need for cross-validation or a separate test set** to get an unbiased estimate of the test set error because of its use of bootstrap sampling for every tree - it is estimated internally, during the run. This ensures that every tree in the forest is built on about 63% of the available data, leaving the remaining approximately 37% for testing [the OOB (out-of-bag) data]. The out-of-bag error gives an accurate estimate of the out of sample error.

So we train the random forest model, and predict the output for the entire training data set.

```{r, results="hide"}
modFit <- randomForest(classe ~ ., data=train.Data2, method="class")
pred <- predict(modFit, train.Data2, type="class")
```

##Results##

Now look at the **confusion matrix** to see how well the model predicts the true output.

```{r, echo=FALSE}
confusionMatrix(pred, train.Data2$classe)
```

The accuracy of this model is computed to be 100%.  It is clear from the confusion matrix that **_the model correctly predicted every one of the test cases_**. This is due to the thorough cleaning that we performed on the data, and the strength of the random forest method.
